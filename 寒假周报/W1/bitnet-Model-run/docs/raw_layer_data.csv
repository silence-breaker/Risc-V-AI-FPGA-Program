Layer Name,Layer Num,Submodule,Type,Category,Time (ms),OPs,Mem Delta (MB),Abs Mem (MB),Input Shape
model.embed_tokens,-1,embed_tokens,Embedding,embedding,0.28745000236085616,7680,0.375,9910.58984375,"[1, 3]"
model.rotary_emb,-1,rotary_emb,BitNetRotaryEmbedding,embedding,0.5347300029825419,7680,2.75,9913.58984375,"[1, 3, 2560]"
model.layers.0.input_layernorm,0,input_layernorm,BitNetRMSNorm,norm,0.24245000167866237,23040,1.125,9914.71484375,"[1, 3, 2560]"
model.layers.0.self_attn.q_proj,0,q_proj,AutoBitLinear,linear,2707.2929970017867,39321600,137.625,10052.33984375,"[1, 3, 2560]"
model.layers.0.self_attn.k_proj,0,k_proj,AutoBitLinear,linear,29.650815999048064,9830400,0.25,10052.58984375,"[1, 3, 2560]"
model.layers.0.self_attn.v_proj,0,v_proj,AutoBitLinear,linear,0.5596489972958807,9830400,0.0,10052.58984375,"[1, 3, 2560]"
model.layers.0.self_attn.attn_sub_norm,0,attn_sub_norm,BitNetRMSNorm,norm,0.12449299902073108,23040,0.0,10053.83984375,"[1, 3, 2560]"
model.layers.0.self_attn.o_proj,0,o_proj,AutoBitLinear,linear,3.5430450006970204,39321600,6.25,10060.08984375,"[1, 3, 2560]"
model.layers.0.post_attention_layernorm,0,post_attention_layernorm,BitNetRMSNorm,norm,0.23135599985835142,23040,0.0,10060.08984375,"[1, 3, 2560]"
model.layers.0.mlp.gate_proj,0,gate_proj,AutoBitLinear,linear,40.47259300205042,106168320,0.421875,10060.51171875,"[1, 3, 2560]"
model.layers.0.mlp.act_fn,0,act_fn,ReLUSquaredActivation,activation,0.13759599823970348,41472,0.0,10060.51171875,"[1, 3, 6912]"
model.layers.0.mlp.up_proj,0,up_proj,AutoBitLinear,linear,11.308581997582223,106168320,0.0,10060.4453125,"[1, 3, 2560]"
model.layers.0.mlp.ffn_sub_norm,0,ffn_sub_norm,BitNetRMSNorm,norm,0.2803509996738285,62208,0.0,10060.4453125,"[1, 3, 6912]"
model.layers.0.mlp.down_proj,0,down_proj,AutoBitLinear,linear,110.40168699764763,106168320,1.69140625,10062.13671875,"[1, 3, 6912]"
model.layers.1.input_layernorm,1,input_layernorm,BitNetRMSNorm,norm,0.18620999981067143,23040,0.0,10062.13671875,"[1, 3, 2560]"
model.layers.1.self_attn.q_proj,1,q_proj,AutoBitLinear,linear,3.2303890002367552,39321600,0.0,10062.13671875,"[1, 3, 2560]"
model.layers.1.self_attn.k_proj,1,k_proj,AutoBitLinear,linear,0.5681940019712783,9830400,0.0,10062.13671875,"[1, 3, 2560]"
model.layers.1.self_attn.v_proj,1,v_proj,AutoBitLinear,linear,0.599588001932716,9830400,0.0,10062.13671875,"[1, 3, 2560]"
model.layers.1.self_attn.attn_sub_norm,1,attn_sub_norm,BitNetRMSNorm,norm,0.13101500007905997,23040,0.0,10062.13671875,"[1, 3, 2560]"
model.layers.1.self_attn.o_proj,1,o_proj,AutoBitLinear,linear,3.375218002474867,39321600,0.0,10062.13671875,"[1, 3, 2560]"
model.layers.1.post_attention_layernorm,1,post_attention_layernorm,BitNetRMSNorm,norm,0.152671000250848,23040,0.0,10062.13671875,"[1, 3, 2560]"
model.layers.1.mlp.gate_proj,1,gate_proj,AutoBitLinear,linear,11.586117998376722,106168320,0.0625,10062.19921875,"[1, 3, 2560]"
model.layers.1.mlp.act_fn,1,act_fn,ReLUSquaredActivation,activation,0.10672300049918704,41472,0.0,10062.19921875,"[1, 3, 6912]"
model.layers.1.mlp.up_proj,1,up_proj,AutoBitLinear,linear,11.37854199987487,106168320,0.0,10062.1328125,"[1, 3, 2560]"
model.layers.1.mlp.ffn_sub_norm,1,ffn_sub_norm,BitNetRMSNorm,norm,0.165253000886878,62208,0.0,10062.1328125,"[1, 3, 6912]"
model.layers.1.mlp.down_proj,1,down_proj,AutoBitLinear,linear,11.495312002807623,106168320,0.05859375,10062.19140625,"[1, 3, 6912]"
model.layers.2.input_layernorm,2,input_layernorm,BitNetRMSNorm,norm,0.16455300283269025,23040,0.0,10062.19140625,"[1, 3, 2560]"
model.layers.2.self_attn.q_proj,2,q_proj,AutoBitLinear,linear,3.4444559969415423,39321600,0.0,10062.19140625,"[1, 3, 2560]"
model.layers.2.self_attn.k_proj,2,k_proj,AutoBitLinear,linear,0.5642180003633257,9830400,0.0,10062.19140625,"[1, 3, 2560]"
model.layers.2.self_attn.v_proj,2,v_proj,AutoBitLinear,linear,0.3721979992405977,9830400,0.0,10062.19140625,"[1, 3, 2560]"
model.layers.2.self_attn.attn_sub_norm,2,attn_sub_norm,BitNetRMSNorm,norm,0.13849699826096185,23040,0.0,10062.19140625,"[1, 3, 2560]"
model.layers.2.self_attn.o_proj,2,o_proj,AutoBitLinear,linear,2.6914150002994575,39321600,0.0,10062.19140625,"[1, 3, 2560]"
model.layers.2.post_attention_layernorm,2,post_attention_layernorm,BitNetRMSNorm,norm,0.13397899965639226,23040,0.0,10062.19140625,"[1, 3, 2560]"
model.layers.2.mlp.gate_proj,2,gate_proj,AutoBitLinear,linear,11.800213997048559,106168320,0.0,10062.125,"[1, 3, 2560]"
model.layers.2.mlp.act_fn,2,act_fn,ReLUSquaredActivation,activation,0.10221499906037934,41472,0.0,10062.125,"[1, 3, 6912]"
model.layers.2.mlp.up_proj,2,up_proj,AutoBitLinear,linear,11.357957002473995,106168320,0.18359375,10062.30859375,"[1, 3, 2560]"
model.layers.2.mlp.ffn_sub_norm,2,ffn_sub_norm,BitNetRMSNorm,norm,0.17922800179803744,62208,0.0,10062.30859375,"[1, 3, 6912]"
model.layers.2.mlp.down_proj,2,down_proj,AutoBitLinear,linear,11.70161600020947,106168320,0.0,10062.1171875,"[1, 3, 6912]"
model.layers.3.input_layernorm,3,input_layernorm,BitNetRMSNorm,norm,0.23118600074667484,23040,0.0,10062.1171875,"[1, 3, 2560]"
model.layers.3.self_attn.q_proj,3,q_proj,AutoBitLinear,linear,3.6318080019555055,39321600,0.0,10062.1171875,"[1, 3, 2560]"
model.layers.3.self_attn.k_proj,3,k_proj,AutoBitLinear,linear,0.6856360014353413,9830400,0.0,10062.1171875,"[1, 3, 2560]"
model.layers.3.self_attn.v_proj,3,v_proj,AutoBitLinear,linear,0.5664009986503515,9830400,0.0,10062.1171875,"[1, 3, 2560]"
model.layers.3.self_attn.attn_sub_norm,3,attn_sub_norm,BitNetRMSNorm,norm,0.17536099767312407,23040,0.0,10062.1171875,"[1, 3, 2560]"
model.layers.3.self_attn.o_proj,3,o_proj,AutoBitLinear,linear,2.9081169996061362,39321600,0.0,10062.1171875,"[1, 3, 2560]"
model.layers.3.post_attention_layernorm,3,post_attention_layernorm,BitNetRMSNorm,norm,0.19340099970577285,23040,0.0,10062.1171875,"[1, 3, 2560]"
model.layers.3.mlp.gate_proj,3,gate_proj,AutoBitLinear,linear,11.544185999809997,106168320,0.1875,10062.3046875,"[1, 3, 2560]"
model.layers.3.mlp.act_fn,3,act_fn,ReLUSquaredActivation,activation,0.10728399865911342,41472,0.0,10062.3046875,"[1, 3, 6912]"
model.layers.3.mlp.up_proj,3,up_proj,AutoBitLinear,linear,11.397595000744332,106168320,0.0,10062.23828125,"[1, 3, 2560]"
model.layers.3.mlp.ffn_sub_norm,3,ffn_sub_norm,BitNetRMSNorm,norm,0.1879720002762042,62208,0.0,10062.23828125,"[1, 3, 6912]"
model.layers.3.mlp.down_proj,3,down_proj,AutoBitLinear,linear,11.08407699939562,106168320,0.05859375,10062.296875,"[1, 3, 6912]"
model.layers.4.input_layernorm,4,input_layernorm,BitNetRMSNorm,norm,0.21588100207736716,23040,0.0,10062.296875,"[1, 3, 2560]"
model.layers.4.self_attn.q_proj,4,q_proj,AutoBitLinear,linear,3.551369998604059,39321600,0.0,10062.296875,"[1, 3, 2560]"
model.layers.4.self_attn.k_proj,4,k_proj,AutoBitLinear,linear,0.5135409992362838,9830400,0.0,10062.296875,"[1, 3, 2560]"
model.layers.4.self_attn.v_proj,4,v_proj,AutoBitLinear,linear,0.36529600038193166,9830400,0.0,10062.296875,"[1, 3, 2560]"
model.layers.4.self_attn.attn_sub_norm,4,attn_sub_norm,BitNetRMSNorm,norm,0.13117499838699587,23040,0.0,10062.296875,"[1, 3, 2560]"
model.layers.4.self_attn.o_proj,4,o_proj,AutoBitLinear,linear,2.6563059982436243,39321600,0.0,10062.296875,"[1, 3, 2560]"
model.layers.4.post_attention_layernorm,4,post_attention_layernorm,BitNetRMSNorm,norm,0.15556699872831814,23040,0.0,10062.296875,"[1, 3, 2560]"
model.layers.4.mlp.gate_proj,4,gate_proj,AutoBitLinear,linear,11.224978999962332,106168320,0.0,10062.23828125,"[1, 3, 2560]"
model.layers.4.mlp.act_fn,4,act_fn,ReLUSquaredActivation,activation,0.09922000026563182,41472,0.0,10062.23828125,"[1, 3, 6912]"
model.layers.4.mlp.up_proj,4,up_proj,AutoBitLinear,linear,11.257785001362208,106168320,0.05859375,10062.296875,"[1, 3, 2560]"
model.layers.4.mlp.ffn_sub_norm,4,ffn_sub_norm,BitNetRMSNorm,norm,0.25179200019920245,62208,0.0,10062.296875,"[1, 3, 6912]"
model.layers.4.mlp.down_proj,4,down_proj,AutoBitLinear,linear,10.844636999536306,106168320,0.0,10062.234375,"[1, 3, 6912]"
model.layers.5.input_layernorm,5,input_layernorm,BitNetRMSNorm,norm,0.1864099976955913,23040,0.0,10062.234375,"[1, 3, 2560]"
model.layers.5.self_attn.q_proj,5,q_proj,AutoBitLinear,linear,3.5827440005959943,39321600,0.0,10062.234375,"[1, 3, 2560]"
model.layers.5.self_attn.k_proj,5,k_proj,AutoBitLinear,linear,0.5482000015035737,9830400,0.0,10062.234375,"[1, 3, 2560]"
model.layers.5.self_attn.v_proj,5,v_proj,AutoBitLinear,linear,0.35892600135412067,9830400,0.0,10062.234375,"[1, 3, 2560]"
model.layers.5.self_attn.attn_sub_norm,5,attn_sub_norm,BitNetRMSNorm,norm,0.10920699787675403,23040,0.0,10062.234375,"[1, 3, 2560]"
model.layers.5.self_attn.o_proj,5,o_proj,AutoBitLinear,linear,3.096370001003379,39321600,0.0,10062.234375,"[1, 3, 2560]"
model.layers.5.post_attention_layernorm,5,post_attention_layernorm,BitNetRMSNorm,norm,0.13732600200455636,23040,0.0,10062.234375,"[1, 3, 2560]"
model.layers.5.mlp.gate_proj,5,gate_proj,AutoBitLinear,linear,11.687551999784773,106168320,0.1875,10062.421875,"[1, 3, 2560]"
model.layers.5.mlp.act_fn,5,act_fn,ReLUSquaredActivation,activation,0.12641699868254364,41472,0.0,10062.421875,"[1, 3, 6912]"
model.layers.5.mlp.up_proj,5,up_proj,AutoBitLinear,linear,11.290690999885555,106168320,0.0,10062.23046875,"[1, 3, 2560]"
model.layers.5.mlp.ffn_sub_norm,5,ffn_sub_norm,BitNetRMSNorm,norm,0.2223209994554054,62208,0.0,10062.23046875,"[1, 3, 6912]"
model.layers.5.mlp.down_proj,5,down_proj,AutoBitLinear,linear,10.51708500017412,106168320,0.05859375,10062.2890625,"[1, 3, 6912]"
model.layers.6.input_layernorm,6,input_layernorm,BitNetRMSNorm,norm,0.16388099902542308,23040,0.0,10062.2890625,"[1, 3, 2560]"
model.layers.6.self_attn.q_proj,6,q_proj,AutoBitLinear,linear,3.6014260003867093,39321600,0.0,10062.2890625,"[1, 3, 2560]"
model.layers.6.self_attn.k_proj,6,k_proj,AutoBitLinear,linear,0.6923070031916723,9830400,0.0,10062.2890625,"[1, 3, 2560]"
model.layers.6.self_attn.v_proj,6,v_proj,AutoBitLinear,linear,0.5072899984952528,9830400,0.0,10062.2890625,"[1, 3, 2560]"
model.layers.6.self_attn.attn_sub_norm,6,attn_sub_norm,BitNetRMSNorm,norm,0.18555799761088565,23040,0.0,10062.2890625,"[1, 3, 2560]"
model.layers.6.self_attn.o_proj,6,o_proj,AutoBitLinear,linear,2.8651630018430296,39321600,0.0,10062.2890625,"[1, 3, 2560]"
model.layers.6.post_attention_layernorm,6,post_attention_layernorm,BitNetRMSNorm,norm,0.20708500233013183,23040,0.0,10062.2890625,"[1, 3, 2560]"
model.layers.6.mlp.gate_proj,6,gate_proj,AutoBitLinear,linear,12.25137899746187,106168320,0.0,10062.23046875,"[1, 3, 2560]"
model.layers.6.mlp.act_fn,6,act_fn,ReLUSquaredActivation,activation,0.12450299982447177,41472,0.0,10062.23046875,"[1, 3, 6912]"
model.layers.6.mlp.up_proj,6,up_proj,AutoBitLinear,linear,11.020838999684202,106168320,0.05859375,10062.2890625,"[1, 3, 2560]"
model.layers.6.mlp.ffn_sub_norm,6,ffn_sub_norm,BitNetRMSNorm,norm,0.2267480012960732,62208,0.0,10062.2890625,"[1, 3, 6912]"
model.layers.6.mlp.down_proj,6,down_proj,AutoBitLinear,linear,9.962914999050554,106168320,0.0,10062.2265625,"[1, 3, 6912]"
model.layers.7.input_layernorm,7,input_layernorm,BitNetRMSNorm,norm,0.1554869995743502,23040,0.0,10062.2265625,"[1, 3, 2560]"
model.layers.7.self_attn.q_proj,7,q_proj,AutoBitLinear,linear,3.2201510002778377,39321600,0.0,10062.2265625,"[1, 3, 2560]"
model.layers.7.self_attn.k_proj,7,k_proj,AutoBitLinear,linear,0.6747179977537598,9830400,0.0,10062.2265625,"[1, 3, 2560]"
model.layers.7.self_attn.v_proj,7,v_proj,AutoBitLinear,linear,0.383967999368906,9830400,0.0,10062.2265625,"[1, 3, 2560]"
model.layers.7.self_attn.attn_sub_norm,7,attn_sub_norm,BitNetRMSNorm,norm,0.1455489982618019,23040,0.0,10062.2265625,"[1, 3, 2560]"
model.layers.7.self_attn.o_proj,7,o_proj,AutoBitLinear,linear,2.7061410000897013,39321600,0.0,10062.2265625,"[1, 3, 2560]"
model.layers.7.post_attention_layernorm,7,post_attention_layernorm,BitNetRMSNorm,norm,0.167958001838997,23040,0.0,10062.2265625,"[1, 3, 2560]"
model.layers.7.mlp.gate_proj,7,gate_proj,AutoBitLinear,linear,12.27235400074278,106168320,0.0625,10062.2890625,"[1, 3, 2560]"
model.layers.7.mlp.act_fn,7,act_fn,ReLUSquaredActivation,activation,0.15488600183743984,41472,0.0,10062.2890625,"[1, 3, 6912]"
model.layers.7.mlp.up_proj,7,up_proj,AutoBitLinear,linear,10.597882999718422,106168320,0.0,10062.22265625,"[1, 3, 2560]"
model.layers.7.mlp.ffn_sub_norm,7,ffn_sub_norm,BitNetRMSNorm,norm,0.21553899932769127,62208,0.0,10062.22265625,"[1, 3, 6912]"
model.layers.7.mlp.down_proj,7,down_proj,AutoBitLinear,linear,10.180767996644136,106168320,0.05859375,10062.28125,"[1, 3, 6912]"
model.layers.8.input_layernorm,8,input_layernorm,BitNetRMSNorm,norm,0.16108600175357424,23040,0.0,10062.28125,"[1, 3, 2560]"
model.layers.8.self_attn.q_proj,8,q_proj,AutoBitLinear,linear,3.291515000455547,39321600,0.0,10062.28125,"[1, 3, 2560]"
model.layers.8.self_attn.k_proj,8,k_proj,AutoBitLinear,linear,0.5669619968102779,9830400,0.0,10062.28125,"[1, 3, 2560]"
model.layers.8.self_attn.v_proj,8,v_proj,AutoBitLinear,linear,0.4693849987233989,9830400,0.0,10062.28125,"[1, 3, 2560]"
model.layers.8.self_attn.attn_sub_norm,8,attn_sub_norm,BitNetRMSNorm,norm,0.09724700066726655,23040,0.0,10062.28125,"[1, 3, 2560]"
model.layers.8.self_attn.o_proj,8,o_proj,AutoBitLinear,linear,2.4157719999493565,39321600,0.0,10062.28125,"[1, 3, 2560]"
model.layers.8.post_attention_layernorm,8,post_attention_layernorm,BitNetRMSNorm,norm,0.28872499751742,23040,0.0,10062.28125,"[1, 3, 2560]"
model.layers.8.mlp.gate_proj,8,gate_proj,AutoBitLinear,linear,12.108762002753792,106168320,0.0703125,10062.3515625,"[1, 3, 2560]"
model.layers.8.mlp.act_fn,8,act_fn,ReLUSquaredActivation,activation,0.15084800179465674,41472,0.0,10062.3515625,"[1, 3, 6912]"
model.layers.8.mlp.up_proj,8,up_proj,AutoBitLinear,linear,11.440169000707101,106168320,0.0,10062.28515625,"[1, 3, 2560]"
model.layers.8.mlp.ffn_sub_norm,8,ffn_sub_norm,BitNetRMSNorm,norm,0.17495999782113358,62208,0.0,10062.28515625,"[1, 3, 6912]"
model.layers.8.mlp.down_proj,8,down_proj,AutoBitLinear,linear,10.367048002080992,106168320,0.0,10062.21875,"[1, 3, 6912]"
model.layers.9.input_layernorm,9,input_layernorm,BitNetRMSNorm,norm,0.18113099940819666,23040,0.0,10062.21875,"[1, 3, 2560]"
model.layers.9.self_attn.q_proj,9,q_proj,AutoBitLinear,linear,3.2551320000493433,39321600,0.0,10062.21875,"[1, 3, 2560]"
model.layers.9.self_attn.k_proj,9,k_proj,AutoBitLinear,linear,0.4560719971777871,9830400,0.0,10062.21875,"[1, 3, 2560]"
model.layers.9.self_attn.v_proj,9,v_proj,AutoBitLinear,linear,0.32342399936169386,9830400,0.0,10062.21875,"[1, 3, 2560]"
model.layers.9.self_attn.attn_sub_norm,9,attn_sub_norm,BitNetRMSNorm,norm,0.09239899736712687,23040,0.0,10062.21875,"[1, 3, 2560]"
model.layers.9.self_attn.o_proj,9,o_proj,AutoBitLinear,linear,2.315780999197159,39321600,0.0,10062.21875,"[1, 3, 2560]"
model.layers.9.post_attention_layernorm,9,post_attention_layernorm,BitNetRMSNorm,norm,0.12219899872434326,23040,0.0,10062.21875,"[1, 3, 2560]"
model.layers.9.mlp.gate_proj,9,gate_proj,AutoBitLinear,linear,12.300353002501652,106168320,0.06640625,10062.28515625,"[1, 3, 2560]"
model.layers.9.mlp.act_fn,9,act_fn,ReLUSquaredActivation,activation,0.15777999942656606,41472,0.0,10062.28515625,"[1, 3, 6912]"
model.layers.9.mlp.up_proj,9,up_proj,AutoBitLinear,linear,11.600132002058672,106168320,0.05859375,10062.34375,"[1, 3, 2560]"
model.layers.9.mlp.ffn_sub_norm,9,ffn_sub_norm,BitNetRMSNorm,norm,0.23442200108547695,62208,0.0,10062.34375,"[1, 3, 6912]"
model.layers.9.mlp.down_proj,9,down_proj,AutoBitLinear,linear,10.734317002061289,106168320,0.0,10062.27734375,"[1, 3, 6912]"
model.layers.10.input_layernorm,10,input_layernorm,BitNetRMSNorm,norm,0.17648299763095565,23040,0.0,10062.27734375,"[1, 3, 2560]"
model.layers.10.self_attn.q_proj,10,q_proj,AutoBitLinear,linear,3.3028239995473996,39321600,0.0,10062.27734375,"[1, 3, 2560]"
model.layers.10.self_attn.k_proj,10,k_proj,AutoBitLinear,linear,0.5698069981008302,9830400,0.0,10062.27734375,"[1, 3, 2560]"
model.layers.10.self_attn.v_proj,10,v_proj,AutoBitLinear,linear,0.4931149996991735,9830400,0.0,10062.27734375,"[1, 3, 2560]"
model.layers.10.self_attn.attn_sub_norm,10,attn_sub_norm,BitNetRMSNorm,norm,0.10979900253005326,23040,0.0,10062.27734375,"[1, 3, 2560]"
model.layers.10.self_attn.o_proj,10,o_proj,AutoBitLinear,linear,2.3715360002825037,39321600,0.0,10062.27734375,"[1, 3, 2560]"
model.layers.10.post_attention_layernorm,10,post_attention_layernorm,BitNetRMSNorm,norm,0.16719699851819314,23040,0.0,10062.27734375,"[1, 3, 2560]"
model.layers.10.mlp.gate_proj,10,gate_proj,AutoBitLinear,linear,11.67584200084093,106168320,0.06640625,10062.34375,"[1, 3, 2560]"
model.layers.10.mlp.act_fn,10,act_fn,ReLUSquaredActivation,activation,0.14623099923483096,41472,0.0,10062.34375,"[1, 3, 6912]"
model.layers.10.mlp.up_proj,10,up_proj,AutoBitLinear,linear,11.421216000599088,106168320,0.05859375,10062.40234375,"[1, 3, 2560]"
model.layers.10.mlp.ffn_sub_norm,10,ffn_sub_norm,BitNetRMSNorm,norm,0.22652799816569313,62208,0.0,10062.40234375,"[1, 3, 6912]"
model.layers.10.mlp.down_proj,10,down_proj,AutoBitLinear,linear,11.2226550008927,106168320,0.0,10062.3359375,"[1, 3, 6912]"
model.layers.11.input_layernorm,11,input_layernorm,BitNetRMSNorm,norm,0.1688699994701892,23040,0.0,10062.3359375,"[1, 3, 2560]"
model.layers.11.self_attn.q_proj,11,q_proj,AutoBitLinear,linear,3.512093000608729,39321600,0.0,10062.3359375,"[1, 3, 2560]"
model.layers.11.self_attn.k_proj,11,k_proj,AutoBitLinear,linear,0.7158570006140508,9830400,0.0,10062.3359375,"[1, 3, 2560]"
model.layers.11.self_attn.v_proj,11,v_proj,AutoBitLinear,linear,0.5457459992612712,9830400,0.0,10062.3359375,"[1, 3, 2560]"
model.layers.11.self_attn.attn_sub_norm,11,attn_sub_norm,BitNetRMSNorm,norm,0.17175399989355356,23040,0.0,10062.3359375,"[1, 3, 2560]"
model.layers.11.self_attn.o_proj,11,o_proj,AutoBitLinear,linear,2.8022949991282076,39321600,0.0,10062.3359375,"[1, 3, 2560]"
model.layers.11.post_attention_layernorm,11,post_attention_layernorm,BitNetRMSNorm,norm,0.19646599685074762,23040,0.0,10062.3359375,"[1, 3, 2560]"
model.layers.11.mlp.gate_proj,11,gate_proj,AutoBitLinear,linear,12.018759996863082,106168320,0.0,10062.27734375,"[1, 3, 2560]"
model.layers.11.mlp.act_fn,11,act_fn,ReLUSquaredActivation,activation,0.13735500033362769,41472,0.0,10062.27734375,"[1, 3, 6912]"
model.layers.11.mlp.up_proj,11,up_proj,AutoBitLinear,linear,10.546224999416154,106168320,0.05859375,10062.3359375,"[1, 3, 2560]"
model.layers.11.mlp.ffn_sub_norm,11,ffn_sub_norm,BitNetRMSNorm,norm,0.19380199955776334,62208,0.0,10062.3359375,"[1, 3, 6912]"
model.layers.11.mlp.down_proj,11,down_proj,AutoBitLinear,linear,10.889342000155011,106168320,0.0,10062.26953125,"[1, 3, 6912]"
model.layers.12.input_layernorm,12,input_layernorm,BitNetRMSNorm,norm,0.15836099919397384,23040,0.0,10062.26953125,"[1, 3, 2560]"
model.layers.12.self_attn.q_proj,12,q_proj,AutoBitLinear,linear,3.652773997600889,39321600,0.0,10062.26953125,"[1, 3, 2560]"
model.layers.12.self_attn.k_proj,12,k_proj,AutoBitLinear,linear,0.7552459974249359,9830400,0.0,10062.26953125,"[1, 3, 2560]"
model.layers.12.self_attn.v_proj,12,v_proj,AutoBitLinear,linear,0.5515060001926031,9830400,0.0,10062.26953125,"[1, 3, 2560]"
model.layers.12.self_attn.attn_sub_norm,12,attn_sub_norm,BitNetRMSNorm,norm,0.17865699919639155,23040,0.0,10062.26953125,"[1, 3, 2560]"
model.layers.12.self_attn.o_proj,12,o_proj,AutoBitLinear,linear,2.789774000120815,39321600,0.0,10062.26953125,"[1, 3, 2560]"
model.layers.12.post_attention_layernorm,12,post_attention_layernorm,BitNetRMSNorm,norm,0.15025800166768022,23040,0.0,10062.26953125,"[1, 3, 2560]"
model.layers.12.mlp.gate_proj,12,gate_proj,AutoBitLinear,linear,12.72843699916848,106168320,0.0,10062.20703125,"[1, 3, 2560]"
model.layers.12.mlp.act_fn,12,act_fn,ReLUSquaredActivation,activation,0.17751499763107859,41472,0.0,10062.20703125,"[1, 3, 6912]"
model.layers.12.mlp.up_proj,12,up_proj,AutoBitLinear,linear,11.38032699964242,106168320,0.05859375,10062.265625,"[1, 3, 2560]"
model.layers.12.mlp.ffn_sub_norm,12,ffn_sub_norm,BitNetRMSNorm,norm,0.2558089981903322,62208,0.0,10062.265625,"[1, 3, 6912]"
model.layers.12.mlp.down_proj,12,down_proj,AutoBitLinear,linear,9.94616599928122,106168320,0.05859375,10062.32421875,"[1, 3, 6912]"
model.layers.13.input_layernorm,13,input_layernorm,BitNetRMSNorm,norm,0.19260000044596381,23040,0.0,10062.32421875,"[1, 3, 2560]"
model.layers.13.self_attn.q_proj,13,q_proj,AutoBitLinear,linear,3.166180002153851,39321600,0.0,10062.32421875,"[1, 3, 2560]"
model.layers.13.self_attn.k_proj,13,k_proj,AutoBitLinear,linear,1.080031997844344,9830400,0.0,10062.32421875,"[1, 3, 2560]"
model.layers.13.self_attn.v_proj,13,v_proj,AutoBitLinear,linear,0.4830489997402765,9830400,0.0,10062.32421875,"[1, 3, 2560]"
model.layers.13.self_attn.attn_sub_norm,13,attn_sub_norm,BitNetRMSNorm,norm,0.11484599963296205,23040,0.0,10062.32421875,"[1, 3, 2560]"
model.layers.13.self_attn.o_proj,13,o_proj,AutoBitLinear,linear,3.0475370003841817,39321600,0.0,10062.32421875,"[1, 3, 2560]"
model.layers.13.post_attention_layernorm,13,post_attention_layernorm,BitNetRMSNorm,norm,0.14532899876940064,23040,0.0,10062.32421875,"[1, 3, 2560]"
model.layers.13.mlp.gate_proj,13,gate_proj,AutoBitLinear,linear,10.387160000391304,106168320,0.0,10062.140625,"[1, 3, 2560]"
model.layers.13.mlp.act_fn,13,act_fn,ReLUSquaredActivation,activation,0.15495499974349514,41472,0.0,10062.140625,"[1, 3, 6912]"
model.layers.13.mlp.up_proj,13,up_proj,AutoBitLinear,linear,10.532402000535512,106168320,0.18359375,10062.32421875,"[1, 3, 2560]"
model.layers.13.mlp.ffn_sub_norm,13,ffn_sub_norm,BitNetRMSNorm,norm,0.18262400044477545,62208,0.0,10062.32421875,"[1, 3, 6912]"
model.layers.13.mlp.down_proj,13,down_proj,AutoBitLinear,linear,12.338668999291258,106168320,0.0,10062.13671875,"[1, 3, 6912]"
model.layers.14.input_layernorm,14,input_layernorm,BitNetRMSNorm,norm,0.2445190002617892,23040,0.0,10062.13671875,"[1, 3, 2560]"
model.layers.14.self_attn.q_proj,14,q_proj,AutoBitLinear,linear,3.8463259988930076,39321600,0.0,10062.13671875,"[1, 3, 2560]"
model.layers.14.self_attn.k_proj,14,k_proj,AutoBitLinear,linear,0.7341089985857252,9830400,0.0,10062.13671875,"[1, 3, 2560]"
model.layers.14.self_attn.v_proj,14,v_proj,AutoBitLinear,linear,0.5339999988791533,9830400,0.0,10062.13671875,"[1, 3, 2560]"
model.layers.14.self_attn.attn_sub_norm,14,attn_sub_norm,BitNetRMSNorm,norm,0.2002399996854365,23040,0.0,10062.13671875,"[1, 3, 2560]"
model.layers.14.self_attn.o_proj,14,o_proj,AutoBitLinear,linear,3.650695001852,39321600,0.0,10062.13671875,"[1, 3, 2560]"
model.layers.14.post_attention_layernorm,14,post_attention_layernorm,BitNetRMSNorm,norm,0.23266399875865318,23040,0.0,10062.13671875,"[1, 3, 2560]"
model.layers.14.mlp.gate_proj,14,gate_proj,AutoBitLinear,linear,12.926127001264831,106168320,0.1875,10062.32421875,"[1, 3, 2560]"
model.layers.14.mlp.act_fn,14,act_fn,ReLUSquaredActivation,activation,0.17429800209356472,41472,0.0,10062.32421875,"[1, 3, 6912]"
model.layers.14.mlp.up_proj,14,up_proj,AutoBitLinear,linear,11.711500999808777,106168320,0.0,10062.1328125,"[1, 3, 2560]"
model.layers.14.mlp.ffn_sub_norm,14,ffn_sub_norm,BitNetRMSNorm,norm,0.18495999756851234,62208,0.0,10062.1328125,"[1, 3, 6912]"
model.layers.14.mlp.down_proj,14,down_proj,AutoBitLinear,linear,10.794738998811226,106168320,0.18359375,10062.31640625,"[1, 3, 6912]"
model.layers.15.input_layernorm,15,input_layernorm,BitNetRMSNorm,norm,0.1631659979466349,23040,0.0,10062.31640625,"[1, 3, 2560]"
model.layers.15.self_attn.q_proj,15,q_proj,AutoBitLinear,linear,3.293009998742491,39321600,0.0,10062.31640625,"[1, 3, 2560]"
model.layers.15.self_attn.k_proj,15,k_proj,AutoBitLinear,linear,0.5820430014864542,9830400,0.0,10062.31640625,"[1, 3, 2560]"
model.layers.15.self_attn.v_proj,15,v_proj,AutoBitLinear,linear,0.4772529973706696,9830400,0.0,10062.31640625,"[1, 3, 2560]"
model.layers.15.self_attn.attn_sub_norm,15,attn_sub_norm,BitNetRMSNorm,norm,0.12567100202431902,23040,0.0,10062.31640625,"[1, 3, 2560]"
model.layers.15.self_attn.o_proj,15,o_proj,AutoBitLinear,linear,2.729443000134779,39321600,0.0,10062.31640625,"[1, 3, 2560]"
model.layers.15.post_attention_layernorm,15,post_attention_layernorm,BitNetRMSNorm,norm,0.2083369981846772,23040,0.0,10062.31640625,"[1, 3, 2560]"
model.layers.15.mlp.gate_proj,15,gate_proj,AutoBitLinear,linear,11.63745200028643,106168320,0.0,10062.14453125,"[1, 3, 2560]"
model.layers.15.mlp.act_fn,15,act_fn,ReLUSquaredActivation,activation,0.11440900198067538,41472,0.0,10062.14453125,"[1, 3, 6912]"
model.layers.15.mlp.up_proj,15,up_proj,AutoBitLinear,linear,11.980829000094673,106168320,0.30859375,10062.453125,"[1, 3, 2560]"
model.layers.15.mlp.ffn_sub_norm,15,ffn_sub_norm,BitNetRMSNorm,norm,0.2782560004561674,62208,0.0,10062.453125,"[1, 3, 6912]"
model.layers.15.mlp.down_proj,15,down_proj,AutoBitLinear,linear,11.3716910018411,106168320,0.0,10062.13671875,"[1, 3, 6912]"
model.layers.16.input_layernorm,16,input_layernorm,BitNetRMSNorm,norm,0.26684399927034974,23040,0.0,10062.13671875,"[1, 3, 2560]"
model.layers.16.self_attn.q_proj,16,q_proj,AutoBitLinear,linear,3.690514000481926,39321600,0.0,10062.13671875,"[1, 3, 2560]"
model.layers.16.self_attn.k_proj,16,k_proj,AutoBitLinear,linear,0.7133050021366216,9830400,0.0,10062.13671875,"[1, 3, 2560]"
model.layers.16.self_attn.v_proj,16,v_proj,AutoBitLinear,linear,0.49728399972082116,9830400,0.0,10062.13671875,"[1, 3, 2560]"
model.layers.16.self_attn.attn_sub_norm,16,attn_sub_norm,BitNetRMSNorm,norm,0.160601000970928,23040,0.0,10062.13671875,"[1, 3, 2560]"
model.layers.16.self_attn.o_proj,16,o_proj,AutoBitLinear,linear,3.3535010006744415,39321600,0.0,10062.13671875,"[1, 3, 2560]"
model.layers.16.post_attention_layernorm,16,post_attention_layernorm,BitNetRMSNorm,norm,0.23871700250310823,23040,0.0,10062.13671875,"[1, 3, 2560]"
model.layers.16.mlp.gate_proj,16,gate_proj,AutoBitLinear,linear,12.403322998579824,106168320,0.16796875,10062.3046875,"[1, 3, 2560]"
model.layers.16.mlp.act_fn,16,act_fn,ReLUSquaredActivation,activation,0.15513999824179336,41472,0.0,10062.3046875,"[1, 3, 6912]"
model.layers.16.mlp.up_proj,16,up_proj,AutoBitLinear,linear,13.445127999148099,106168320,0.0,10062.11328125,"[1, 3, 2560]"
model.layers.16.mlp.ffn_sub_norm,16,ffn_sub_norm,BitNetRMSNorm,norm,0.18342700059292838,62208,0.0,10062.11328125,"[1, 3, 6912]"
model.layers.16.mlp.down_proj,16,down_proj,AutoBitLinear,linear,13.025970998569392,106168320,0.24609375,10062.359375,"[1, 3, 6912]"
model.layers.17.input_layernorm,17,input_layernorm,BitNetRMSNorm,norm,0.23914900157251395,23040,0.0,10062.359375,"[1, 3, 2560]"
model.layers.17.self_attn.q_proj,17,q_proj,AutoBitLinear,linear,3.592519999074284,39321600,0.0,10062.359375,"[1, 3, 2560]"
model.layers.17.self_attn.k_proj,17,k_proj,AutoBitLinear,linear,0.9296909993281588,9830400,0.0,10062.359375,"[1, 3, 2560]"
model.layers.17.self_attn.v_proj,17,v_proj,AutoBitLinear,linear,0.6113130002631806,9830400,0.0,10062.359375,"[1, 3, 2560]"
model.layers.17.self_attn.attn_sub_norm,17,attn_sub_norm,BitNetRMSNorm,norm,0.16861699987202883,23040,0.0,10062.359375,"[1, 3, 2560]"
model.layers.17.self_attn.o_proj,17,o_proj,AutoBitLinear,linear,2.9927790019428357,39321600,0.0,10062.359375,"[1, 3, 2560]"
model.layers.17.post_attention_layernorm,17,post_attention_layernorm,BitNetRMSNorm,norm,0.21864800146431662,23040,0.0,10062.359375,"[1, 3, 2560]"
model.layers.17.mlp.gate_proj,17,gate_proj,AutoBitLinear,linear,12.085296999430284,106168320,0.0,10062.12890625,"[1, 3, 2560]"
model.layers.17.mlp.act_fn,17,act_fn,ReLUSquaredActivation,activation,0.1386580006510485,41472,0.0,10062.12890625,"[1, 3, 6912]"
model.layers.17.mlp.up_proj,17,up_proj,AutoBitLinear,linear,11.8533809982182,106168320,0.3125,10062.44140625,"[1, 3, 2560]"
model.layers.17.mlp.ffn_sub_norm,17,ffn_sub_norm,BitNetRMSNorm,norm,0.24038099945755675,62208,0.0,10062.44140625,"[1, 3, 6912]"
model.layers.17.mlp.down_proj,17,down_proj,AutoBitLinear,linear,13.004248001379892,106168320,0.0,10062.125,"[1, 3, 6912]"
model.layers.18.input_layernorm,18,input_layernorm,BitNetRMSNorm,norm,0.22646300203632563,23040,0.0,10062.125,"[1, 3, 2560]"
model.layers.18.self_attn.q_proj,18,q_proj,AutoBitLinear,linear,3.783282001677435,39321600,0.0,10062.125,"[1, 3, 2560]"
model.layers.18.self_attn.k_proj,18,k_proj,AutoBitLinear,linear,0.8591599980718456,9830400,0.0,10062.125,"[1, 3, 2560]"
model.layers.18.self_attn.v_proj,18,v_proj,AutoBitLinear,linear,0.5661530012730509,9830400,0.0,10062.125,"[1, 3, 2560]"
model.layers.18.self_attn.attn_sub_norm,18,attn_sub_norm,BitNetRMSNorm,norm,0.1915440006996505,23040,0.0,10062.125,"[1, 3, 2560]"
model.layers.18.self_attn.o_proj,18,o_proj,AutoBitLinear,linear,3.1946430026437156,39321600,0.0,10062.125,"[1, 3, 2560]"
model.layers.18.post_attention_layernorm,18,post_attention_layernorm,BitNetRMSNorm,norm,0.20120200133533217,23040,0.0,10062.125,"[1, 3, 2560]"
model.layers.18.mlp.gate_proj,18,gate_proj,AutoBitLinear,linear,13.077593997877557,106168320,0.27734375,10062.40234375,"[1, 3, 2560]"
model.layers.18.mlp.act_fn,18,act_fn,ReLUSquaredActivation,activation,0.1431969976692926,41472,0.0,10062.40234375,"[1, 3, 6912]"
model.layers.18.mlp.up_proj,18,up_proj,AutoBitLinear,linear,12.974656998267164,106168320,0.0,10062.265625,"[1, 3, 2560]"
model.layers.18.mlp.ffn_sub_norm,18,ffn_sub_norm,BitNetRMSNorm,norm,0.28353699963190593,62208,0.0,10062.265625,"[1, 3, 6912]"
model.layers.18.mlp.down_proj,18,down_proj,AutoBitLinear,linear,11.356668001099024,106168320,0.05859375,10062.32421875,"[1, 3, 6912]"
model.layers.19.input_layernorm,19,input_layernorm,BitNetRMSNorm,norm,0.2580660002422519,23040,0.0,10062.32421875,"[1, 3, 2560]"
model.layers.19.self_attn.q_proj,19,q_proj,AutoBitLinear,linear,3.5148749993823003,39321600,0.0,10062.32421875,"[1, 3, 2560]"
model.layers.19.self_attn.k_proj,19,k_proj,AutoBitLinear,linear,0.7281779980985448,9830400,0.0,10062.32421875,"[1, 3, 2560]"
model.layers.19.self_attn.v_proj,19,v_proj,AutoBitLinear,linear,0.5593300011241809,9830400,0.0,10062.32421875,"[1, 3, 2560]"
model.layers.19.self_attn.attn_sub_norm,19,attn_sub_norm,BitNetRMSNorm,norm,0.1663530019868631,23040,0.0,10062.32421875,"[1, 3, 2560]"
model.layers.19.self_attn.o_proj,19,o_proj,AutoBitLinear,linear,2.8446249998523854,39321600,0.0,10062.32421875,"[1, 3, 2560]"
model.layers.19.post_attention_layernorm,19,post_attention_layernorm,BitNetRMSNorm,norm,0.15097199866431765,23040,0.0,10062.32421875,"[1, 3, 2560]"
model.layers.19.mlp.gate_proj,19,gate_proj,AutoBitLinear,linear,11.69273200139287,106168320,0.0,10062.3203125,"[1, 3, 2560]"
model.layers.19.mlp.act_fn,19,act_fn,ReLUSquaredActivation,activation,0.16015999790397473,41472,0.0,10062.3203125,"[1, 3, 6912]"
model.layers.19.mlp.up_proj,19,up_proj,AutoBitLinear,linear,11.107800997706363,106168320,0.18359375,10062.50390625,"[1, 3, 2560]"
model.layers.19.mlp.ffn_sub_norm,19,ffn_sub_norm,BitNetRMSNorm,norm,0.18180400002165698,62208,0.0,10062.50390625,"[1, 3, 6912]"
model.layers.19.mlp.down_proj,19,down_proj,AutoBitLinear,linear,11.980849001702154,106168320,0.0,10062.31640625,"[1, 3, 6912]"
model.layers.20.input_layernorm,20,input_layernorm,BitNetRMSNorm,norm,0.242505000642268,23040,0.0,10062.31640625,"[1, 3, 2560]"
model.layers.20.self_attn.q_proj,20,q_proj,AutoBitLinear,linear,3.596628001105273,39321600,0.0,10062.31640625,"[1, 3, 2560]"
model.layers.20.self_attn.k_proj,20,k_proj,AutoBitLinear,linear,0.7309729990083724,9830400,0.0,10062.31640625,"[1, 3, 2560]"
model.layers.20.self_attn.v_proj,20,v_proj,AutoBitLinear,linear,0.5584069986070972,9830400,0.0,10062.31640625,"[1, 3, 2560]"
model.layers.20.self_attn.attn_sub_norm,20,attn_sub_norm,BitNetRMSNorm,norm,0.16925800082390197,23040,0.0,10062.31640625,"[1, 3, 2560]"
model.layers.20.self_attn.o_proj,20,o_proj,AutoBitLinear,linear,2.864622998458799,39321600,0.0,10062.31640625,"[1, 3, 2560]"
model.layers.20.post_attention_layernorm,20,post_attention_layernorm,BitNetRMSNorm,norm,0.2091289970849175,23040,0.0,10062.31640625,"[1, 3, 2560]"
model.layers.20.mlp.gate_proj,20,gate_proj,AutoBitLinear,linear,11.837221001769649,106168320,0.06640625,10062.3828125,"[1, 3, 2560]"
model.layers.20.mlp.act_fn,20,act_fn,ReLUSquaredActivation,activation,0.147414997627493,41472,0.0,10062.3828125,"[1, 3, 6912]"
model.layers.20.mlp.up_proj,20,up_proj,AutoBitLinear,linear,11.417932000767905,106168320,0.0,10062.31640625,"[1, 3, 2560]"
model.layers.20.mlp.ffn_sub_norm,20,ffn_sub_norm,BitNetRMSNorm,norm,0.1699799977359362,62208,0.0,10062.31640625,"[1, 3, 6912]"
model.layers.20.mlp.down_proj,20,down_proj,AutoBitLinear,linear,11.004955998942023,106168320,0.18359375,10062.5,"[1, 3, 6912]"
model.layers.21.input_layernorm,21,input_layernorm,BitNetRMSNorm,norm,0.27009000041289255,23040,0.0,10062.5,"[1, 3, 2560]"
model.layers.21.self_attn.q_proj,21,q_proj,AutoBitLinear,linear,3.507539997372078,39321600,0.0,10062.5,"[1, 3, 2560]"
model.layers.21.self_attn.k_proj,21,k_proj,AutoBitLinear,linear,0.6969839996600058,9830400,0.0,10062.5,"[1, 3, 2560]"
model.layers.21.self_attn.v_proj,21,v_proj,AutoBitLinear,linear,0.5297610005072784,9830400,0.0,10062.5,"[1, 3, 2560]"
model.layers.21.self_attn.attn_sub_norm,21,attn_sub_norm,BitNetRMSNorm,norm,0.17362799917464145,23040,0.0,10062.5,"[1, 3, 2560]"
model.layers.21.self_attn.o_proj,21,o_proj,AutoBitLinear,linear,2.960204001283273,39321600,0.0,10062.5,"[1, 3, 2560]"
model.layers.21.post_attention_layernorm,21,post_attention_layernorm,BitNetRMSNorm,norm,0.22412899852497503,23040,0.0,10062.5,"[1, 3, 2560]"
model.layers.21.mlp.gate_proj,21,gate_proj,AutoBitLinear,linear,11.43921399852843,106168320,0.0,10062.31640625,"[1, 3, 2560]"
model.layers.21.mlp.act_fn,21,act_fn,ReLUSquaredActivation,activation,0.14993999866419472,41472,0.0,10062.31640625,"[1, 3, 6912]"
model.layers.21.mlp.up_proj,21,up_proj,AutoBitLinear,linear,11.588221997953951,106168320,0.1875,10062.50390625,"[1, 3, 2560]"
model.layers.21.mlp.ffn_sub_norm,21,ffn_sub_norm,BitNetRMSNorm,norm,0.2877360020647757,62208,0.0,10062.50390625,"[1, 3, 6912]"
model.layers.21.mlp.down_proj,21,down_proj,AutoBitLinear,linear,11.812111999461195,106168320,0.0,10062.31640625,"[1, 3, 6912]"
model.layers.22.input_layernorm,22,input_layernorm,BitNetRMSNorm,norm,0.24077199850580655,23040,0.0,10062.31640625,"[1, 3, 2560]"
model.layers.22.self_attn.q_proj,22,q_proj,AutoBitLinear,linear,3.6618589983845595,39321600,0.0,10062.31640625,"[1, 3, 2560]"
model.layers.22.self_attn.k_proj,22,k_proj,AutoBitLinear,linear,0.7208019997051451,9830400,0.0,10062.31640625,"[1, 3, 2560]"
model.layers.22.self_attn.v_proj,22,v_proj,AutoBitLinear,linear,0.5427460018836427,9830400,0.0,10062.31640625,"[1, 3, 2560]"
model.layers.22.self_attn.attn_sub_norm,22,attn_sub_norm,BitNetRMSNorm,norm,0.1855409973359201,23040,0.0,10062.31640625,"[1, 3, 2560]"
model.layers.22.self_attn.o_proj,22,o_proj,AutoBitLinear,linear,2.8865269996458665,39321600,0.0,10062.31640625,"[1, 3, 2560]"
model.layers.22.post_attention_layernorm,22,post_attention_layernorm,BitNetRMSNorm,norm,0.21110300076543353,23040,0.0,10062.31640625,"[1, 3, 2560]"
model.layers.22.mlp.gate_proj,22,gate_proj,AutoBitLinear,linear,11.46194000102696,106168320,0.0,10062.31640625,"[1, 3, 2560]"
model.layers.22.mlp.act_fn,22,act_fn,ReLUSquaredActivation,activation,0.1073949970304966,41472,0.0,10062.31640625,"[1, 3, 6912]"
model.layers.22.mlp.up_proj,22,up_proj,AutoBitLinear,linear,12.130637998780003,106168320,0.05859375,10062.375,"[1, 3, 2560]"
model.layers.22.mlp.ffn_sub_norm,22,ffn_sub_norm,BitNetRMSNorm,norm,0.2718940013437532,62208,0.0,10062.375,"[1, 3, 6912]"
model.layers.22.mlp.down_proj,22,down_proj,AutoBitLinear,linear,11.507963001349708,106168320,0.05859375,10062.43359375,"[1, 3, 6912]"
model.layers.23.input_layernorm,23,input_layernorm,BitNetRMSNorm,norm,0.17410799773642793,23040,0.0,10062.43359375,"[1, 3, 2560]"
model.layers.23.self_attn.q_proj,23,q_proj,AutoBitLinear,linear,3.9988509997783694,39321600,0.0,10062.43359375,"[1, 3, 2560]"
model.layers.23.self_attn.k_proj,23,k_proj,AutoBitLinear,linear,0.6291389981925022,9830400,0.0,10062.43359375,"[1, 3, 2560]"
model.layers.23.self_attn.v_proj,23,v_proj,AutoBitLinear,linear,0.47385799916810356,9830400,0.0,10062.43359375,"[1, 3, 2560]"
model.layers.23.self_attn.attn_sub_norm,23,attn_sub_norm,BitNetRMSNorm,norm,0.1229859990417026,23040,0.0,10062.43359375,"[1, 3, 2560]"
model.layers.23.self_attn.o_proj,23,o_proj,AutoBitLinear,linear,2.773069998511346,39321600,0.0,10062.43359375,"[1, 3, 2560]"
model.layers.23.post_attention_layernorm,23,post_attention_layernorm,BitNetRMSNorm,norm,0.22669400277663954,23040,0.0,10062.43359375,"[1, 3, 2560]"
model.layers.23.mlp.gate_proj,23,gate_proj,AutoBitLinear,linear,11.95395600007032,106168320,0.0,10062.37109375,"[1, 3, 2560]"
model.layers.23.mlp.act_fn,23,act_fn,ReLUSquaredActivation,activation,0.14621300215367228,41472,0.0,10062.37109375,"[1, 3, 6912]"
model.layers.23.mlp.up_proj,23,up_proj,AutoBitLinear,linear,11.679875999107026,106168320,0.05859375,10062.4296875,"[1, 3, 2560]"
model.layers.23.mlp.ffn_sub_norm,23,ffn_sub_norm,BitNetRMSNorm,norm,0.17019999722833745,62208,0.0,10062.4296875,"[1, 3, 6912]"
model.layers.23.mlp.down_proj,23,down_proj,AutoBitLinear,linear,10.640255997714121,106168320,0.0,10062.36328125,"[1, 3, 6912]"
model.layers.24.input_layernorm,24,input_layernorm,BitNetRMSNorm,norm,0.17377800031681545,23040,0.0,10062.36328125,"[1, 3, 2560]"
model.layers.24.self_attn.q_proj,24,q_proj,AutoBitLinear,linear,3.6432609995245,39321600,0.0,10062.36328125,"[1, 3, 2560]"
model.layers.24.self_attn.k_proj,24,k_proj,AutoBitLinear,linear,0.8626060007372871,9830400,0.0,10062.36328125,"[1, 3, 2560]"
model.layers.24.self_attn.v_proj,24,v_proj,AutoBitLinear,linear,0.5771150026703253,9830400,0.0,10062.36328125,"[1, 3, 2560]"
model.layers.24.self_attn.attn_sub_norm,24,attn_sub_norm,BitNetRMSNorm,norm,0.1602810007170774,23040,0.0,10062.36328125,"[1, 3, 2560]"
model.layers.24.self_attn.o_proj,24,o_proj,AutoBitLinear,linear,3.255936000641668,39321600,0.0,10062.36328125,"[1, 3, 2560]"
model.layers.24.post_attention_layernorm,24,post_attention_layernorm,BitNetRMSNorm,norm,0.2007020011660643,23040,0.0,10062.36328125,"[1, 3, 2560]"
model.layers.24.mlp.gate_proj,24,gate_proj,AutoBitLinear,linear,12.624917999346508,106168320,0.06640625,10062.4296875,"[1, 3, 2560]"
model.layers.24.mlp.act_fn,24,act_fn,ReLUSquaredActivation,activation,0.14495999857899733,41472,0.0,10062.4296875,"[1, 3, 6912]"
model.layers.24.mlp.up_proj,24,up_proj,AutoBitLinear,linear,11.269725000602193,106168320,0.0,10062.36328125,"[1, 3, 2560]"
model.layers.24.mlp.ffn_sub_norm,24,ffn_sub_norm,BitNetRMSNorm,norm,0.24843700157362036,62208,0.0,10062.36328125,"[1, 3, 6912]"
model.layers.24.mlp.down_proj,24,down_proj,AutoBitLinear,linear,10.758151998743415,106168320,0.0,10062.30078125,"[1, 3, 6912]"
model.layers.25.input_layernorm,25,input_layernorm,BitNetRMSNorm,norm,0.16209499881369993,23040,0.0,10062.30078125,"[1, 3, 2560]"
model.layers.25.self_attn.q_proj,25,q_proj,AutoBitLinear,linear,3.590385000279639,39321600,0.0,10062.30078125,"[1, 3, 2560]"
model.layers.25.self_attn.k_proj,25,k_proj,AutoBitLinear,linear,0.7306320003408473,9830400,0.0,10062.30078125,"[1, 3, 2560]"
model.layers.25.self_attn.v_proj,25,v_proj,AutoBitLinear,linear,0.5718040010833647,9830400,0.0,10062.30078125,"[1, 3, 2560]"
model.layers.25.self_attn.attn_sub_norm,25,attn_sub_norm,BitNetRMSNorm,norm,0.1527759995951783,23040,0.0,10062.30078125,"[1, 3, 2560]"
model.layers.25.self_attn.o_proj,25,o_proj,AutoBitLinear,linear,2.845334998710314,39321600,0.0,10062.30078125,"[1, 3, 2560]"
model.layers.25.post_attention_layernorm,25,post_attention_layernorm,BitNetRMSNorm,norm,0.20604200108209625,23040,0.0,10062.30078125,"[1, 3, 2560]"
model.layers.25.mlp.gate_proj,25,gate_proj,AutoBitLinear,linear,11.794064001151128,106168320,0.0625,10062.36328125,"[1, 3, 2560]"
model.layers.25.mlp.act_fn,25,act_fn,ReLUSquaredActivation,activation,0.1505109976278618,41472,0.0,10062.36328125,"[1, 3, 6912]"
model.layers.25.mlp.up_proj,25,up_proj,AutoBitLinear,linear,11.438162000558805,106168320,0.0,10062.296875,"[1, 3, 2560]"
model.layers.25.mlp.ffn_sub_norm,25,ffn_sub_norm,BitNetRMSNorm,norm,0.21195400040596724,62208,0.0,10062.296875,"[1, 3, 6912]"
model.layers.25.mlp.down_proj,25,down_proj,AutoBitLinear,linear,11.572219998924993,106168320,0.05859375,10062.35546875,"[1, 3, 6912]"
model.layers.26.input_layernorm,26,input_layernorm,BitNetRMSNorm,norm,0.2501499984646216,23040,0.0,10062.35546875,"[1, 3, 2560]"
model.layers.26.self_attn.q_proj,26,q_proj,AutoBitLinear,linear,3.994906001025811,39321600,0.0,10062.35546875,"[1, 3, 2560]"
model.layers.26.self_attn.k_proj,26,k_proj,AutoBitLinear,linear,0.7830969989299774,9830400,0.0,10062.35546875,"[1, 3, 2560]"
model.layers.26.self_attn.v_proj,26,v_proj,AutoBitLinear,linear,0.5715240004064981,9830400,0.0,10062.35546875,"[1, 3, 2560]"
model.layers.26.self_attn.attn_sub_norm,26,attn_sub_norm,BitNetRMSNorm,norm,0.18467900008545257,23040,0.0,10062.35546875,"[1, 3, 2560]"
model.layers.26.self_attn.o_proj,26,o_proj,AutoBitLinear,linear,3.1196039999485947,39321600,0.0,10062.35546875,"[1, 3, 2560]"
model.layers.26.post_attention_layernorm,26,post_attention_layernorm,BitNetRMSNorm,norm,0.21112200192874297,23040,0.0,10062.35546875,"[1, 3, 2560]"
model.layers.26.mlp.gate_proj,26,gate_proj,AutoBitLinear,linear,12.167763001343701,106168320,0.0,10062.35546875,"[1, 3, 2560]"
model.layers.26.mlp.act_fn,26,act_fn,ReLUSquaredActivation,activation,0.17661400124779902,41472,0.0,10062.35546875,"[1, 3, 6912]"
model.layers.26.mlp.up_proj,26,up_proj,AutoBitLinear,linear,11.050275999878068,106168320,0.05859375,10062.4140625,"[1, 3, 2560]"
model.layers.26.mlp.ffn_sub_norm,26,ffn_sub_norm,BitNetRMSNorm,norm,0.2561030014476273,62208,0.0,10062.4140625,"[1, 3, 6912]"
model.layers.26.mlp.down_proj,26,down_proj,AutoBitLinear,linear,11.051166002289392,106168320,0.05859375,10062.47265625,"[1, 3, 6912]"
model.layers.27.input_layernorm,27,input_layernorm,BitNetRMSNorm,norm,0.1651109996601008,23040,0.0,10062.47265625,"[1, 3, 2560]"
model.layers.27.self_attn.q_proj,27,q_proj,AutoBitLinear,linear,3.5925310003221966,39321600,0.0,10062.47265625,"[1, 3, 2560]"
model.layers.27.self_attn.k_proj,27,k_proj,AutoBitLinear,linear,0.6307130024651997,9830400,0.0,10062.47265625,"[1, 3, 2560]"
model.layers.27.self_attn.v_proj,27,v_proj,AutoBitLinear,linear,0.44532199899549596,9830400,0.0,10062.47265625,"[1, 3, 2560]"
model.layers.27.self_attn.attn_sub_norm,27,attn_sub_norm,BitNetRMSNorm,norm,0.10624199785524979,23040,0.0,10062.47265625,"[1, 3, 2560]"
model.layers.27.self_attn.o_proj,27,o_proj,AutoBitLinear,linear,2.700615001231199,39321600,0.0,10062.47265625,"[1, 3, 2560]"
model.layers.27.post_attention_layernorm,27,post_attention_layernorm,BitNetRMSNorm,norm,0.17431900050723925,23040,0.0,10062.47265625,"[1, 3, 2560]"
model.layers.27.mlp.gate_proj,27,gate_proj,AutoBitLinear,linear,11.495507998915855,106168320,0.0,10062.4140625,"[1, 3, 2560]"
model.layers.27.mlp.act_fn,27,act_fn,ReLUSquaredActivation,activation,0.10566099808784202,41472,0.0,10062.4140625,"[1, 3, 6912]"
model.layers.27.mlp.up_proj,27,up_proj,AutoBitLinear,linear,11.129574999358738,106168320,0.0625,10062.4765625,"[1, 3, 2560]"
model.layers.27.mlp.ffn_sub_norm,27,ffn_sub_norm,BitNetRMSNorm,norm,0.16806600251584314,62208,0.0,10062.4765625,"[1, 3, 6912]"
model.layers.27.mlp.down_proj,27,down_proj,AutoBitLinear,linear,11.495095001009759,106168320,0.0,10062.4140625,"[1, 3, 6912]"
model.layers.28.input_layernorm,28,input_layernorm,BitNetRMSNorm,norm,0.2634670017869212,23040,0.0,10062.4140625,"[1, 3, 2560]"
model.layers.28.self_attn.q_proj,28,q_proj,AutoBitLinear,linear,3.4959869990416337,39321600,0.0,10062.4140625,"[1, 3, 2560]"
model.layers.28.self_attn.k_proj,28,k_proj,AutoBitLinear,linear,0.9230290015693754,9830400,0.0,10062.4140625,"[1, 3, 2560]"
model.layers.28.self_attn.v_proj,28,v_proj,AutoBitLinear,linear,0.5387780001910869,9830400,0.0,10062.4140625,"[1, 3, 2560]"
model.layers.28.self_attn.attn_sub_norm,28,attn_sub_norm,BitNetRMSNorm,norm,0.17134299923782237,23040,0.0,10062.4140625,"[1, 3, 2560]"
model.layers.28.self_attn.o_proj,28,o_proj,AutoBitLinear,linear,2.865766000468284,39321600,0.0,10062.4140625,"[1, 3, 2560]"
model.layers.28.post_attention_layernorm,28,post_attention_layernorm,BitNetRMSNorm,norm,0.1975759987544734,23040,0.0,10062.4140625,"[1, 3, 2560]"
model.layers.28.mlp.gate_proj,28,gate_proj,AutoBitLinear,linear,11.65308300187462,106168320,0.0625,10062.4765625,"[1, 3, 2560]"
model.layers.28.mlp.act_fn,28,act_fn,ReLUSquaredActivation,activation,0.10976999692502432,41472,0.0,10062.4765625,"[1, 3, 6912]"
model.layers.28.mlp.up_proj,28,up_proj,AutoBitLinear,linear,11.415987999498611,106168320,0.0,10062.41015625,"[1, 3, 2560]"
model.layers.28.mlp.ffn_sub_norm,28,ffn_sub_norm,BitNetRMSNorm,norm,0.1923950003401842,62208,0.0,10062.41015625,"[1, 3, 6912]"
model.layers.28.mlp.down_proj,28,down_proj,AutoBitLinear,linear,11.8346740018751,106168320,0.05859375,10062.46875,"[1, 3, 6912]"
model.layers.29.input_layernorm,29,input_layernorm,BitNetRMSNorm,norm,0.18384800205240026,23040,0.0,10062.46875,"[1, 3, 2560]"
model.layers.29.self_attn.q_proj,29,q_proj,AutoBitLinear,linear,3.4209869991173036,39321600,0.0,10062.46875,"[1, 3, 2560]"
model.layers.29.self_attn.k_proj,29,k_proj,AutoBitLinear,linear,0.7107729979907162,9830400,0.0,10062.46875,"[1, 3, 2560]"
model.layers.29.self_attn.v_proj,29,v_proj,AutoBitLinear,linear,0.5057719972683117,9830400,0.0,10062.46875,"[1, 3, 2560]"
model.layers.29.self_attn.attn_sub_norm,29,attn_sub_norm,BitNetRMSNorm,norm,0.17093199858209118,23040,0.0,10062.46875,"[1, 3, 2560]"
model.layers.29.self_attn.o_proj,29,o_proj,AutoBitLinear,linear,2.8668880004261155,39321600,0.0,10062.46875,"[1, 3, 2560]"
model.layers.29.post_attention_layernorm,29,post_attention_layernorm,BitNetRMSNorm,norm,0.20780600243597291,23040,0.0,10062.46875,"[1, 3, 2560]"
model.layers.29.mlp.gate_proj,29,gate_proj,AutoBitLinear,linear,11.858855999889784,106168320,0.0,10062.41015625,"[1, 3, 2560]"
model.layers.29.mlp.act_fn,29,act_fn,ReLUSquaredActivation,activation,0.12013100058538839,41472,0.0,10062.41015625,"[1, 3, 6912]"
model.layers.29.mlp.up_proj,29,up_proj,AutoBitLinear,linear,11.574626001674915,106168320,0.18359375,10062.59375,"[1, 3, 2560]"
model.layers.29.mlp.ffn_sub_norm,29,ffn_sub_norm,BitNetRMSNorm,norm,0.25728499895194545,62208,0.0,10062.59375,"[1, 3, 6912]"
model.layers.29.mlp.down_proj,29,down_proj,AutoBitLinear,linear,11.153752999234712,106168320,0.0,10062.40234375,"[1, 3, 6912]"
model.norm,-1,norm,BitNetRMSNorm,norm,0.1710719989205245,23040,0.0,10062.40234375,"[1, 3, 2560]"
lm_head,-1,lm_head,Linear,linear,81.23970399901737,1970012160,0.0,10062.40234375,"[1, 3, 2560]"
